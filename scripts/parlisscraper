#! python
'''
Created on 25.06.2011

@author: niko
'''
import datetime
import logging
from optparse import OptionParser

from parlisscraper.exporters import CSVExporter, XMLExporter
from parlisscraper.indexfinder import ParlisIndexFinder
from parlisscraper.scraper import ParlisScraper

LOGGER = logging.getLogger('parlisscraper')


def startWorkflow(startYear=None, endYear=None, onlySearchIndexes=False,
                  onlyScrapeFiles=False):
    if startYear is None:
        startYear = 1992

    if endYear is None:
        endYear = datetime.date.today().year

    for year in range(startYear, endYear + 1):
        LOGGER.info("Processing year {0}".format(year))

        if not onlyScrapeFiles:
            LOGGER.info("Start looking for indexes")
            indexer = ParlisIndexFinder(year)
            indexer.startSearching()
            LOGGER.info("Finished looking for indexes")

        if not onlySearchIndexes:
            scrape = ParlisScraper(year)

            scrapingResults = scrape.startScraping()
            try:
                csvExporter = CSVExporter(scrape.outputFile)
                csvExporter.createExport(scrapingResults)
            except Exception as err:
                LOGGER.error("Failed to write CSV. Writing XML. Error: {0}".format(err))
                xmlExporter = XMLExporter('%s.xml' % scrape.outputFile)
                xmlExporter.createExport(scrapingResults)


if __name__ == '__main__':
    optionParser = OptionParser()
    optionParser.add_option('-s', '--startYear', dest='startYear', type=int,
                            default=1992,
                            help='The year from which one the scraping starts')
    optionParser.add_option('-e', '--endYear', dest='endYear', type=int,
                            default=None,
                            help='The year to which the scraping will work')
    optionParser.add_option('-i', '--onlyIndexes', dest='onlyIndexes',
                            default=False, action="store_true",
                            help='Only create index files.')
    optionParser.add_option('-d', '--onlyScraping', dest='onlyScraping',
                            default=False, action="store_true",
                            help='Only scrape webpages.')
    optionParser.add_option('--debug', action="store_true", default=False,
                            help="Enable debug output.")
    optionParser.add_option('--verbose', action="store_true", default=False,
                            help="Verbose output.")

    (options, unparseableArguments) = optionParser.parse_args()

    if options.debug:
        logging.basicConfig(level=logging.DEBUG)
    elif options.verbose:
        logging.basicConfig(level=logging.INFO)
    else:
        logging.basicConfig(level=logging.ERROR)

    startWorkflow(options.startYear, options.endYear,
                  options.onlyIndexes, options.onlyScraping)
